{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Person():\n",
    "\t\"\"\" Person (parent?) class -- will define how the person takes in a points signal and puts out an energy signal \n",
    "\tbaseline_energy = a list or dataframe of values. This is data from SinBerBEST \n",
    "\tpoints_multiplier = an int which describes how sensitive each person is to points \n",
    "\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, baseline_energy_df, points_multiplier = 1):\n",
    "\t\tself.baseline_energy_df = baseline_energy_df\n",
    "\t\tself.baseline_energy = np.array(self.baseline_energy_df[\"net_energy_use\"])\n",
    "\t\tself.points_multiplier = points_multiplier\n",
    "\t\t\n",
    "\t\tbaseline_min = self.baseline_energy.min()\n",
    "\t\tbaseline_max = self.baseline_energy.max()\n",
    "\t\tbaseline_range = baseline_max - baseline_min\n",
    "\t\t\n",
    "\t\tself.min_demand = np.maximum(0, baseline_min + baseline_range * .05)\n",
    "\t\tself.max_demand = np.maximum(0, baseline_min + baseline_range * .95)\n",
    "\n",
    "\n",
    "\tdef energy_output_simple_linear(self, points):\n",
    "\t\t\"\"\"Determines the energy output of the person, based on the formula:\n",
    "\t\t\n",
    "\t\ty[n] = -sum_{rolling window of 5} points + baseline_energy + noise\n",
    "\n",
    "\t\tinputs: points - list or dataframe of points values. Assumes that the \n",
    "\t\tlist will be in the same time increment that energy_output will be. \n",
    "\n",
    "\t\tFor now, that's in 1 hour increments\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\tpoints_df = pd.DataFrame(points)\n",
    "\t\t\n",
    "\t\tpoints_effect = (\n",
    "\t\t\tpoints_df\n",
    "\t\t\t\t.rolling(\n",
    "\t\t\t\t\t\twindow = 5,\n",
    "\t\t\t\t\t\tmin_periods = 1)\n",
    "\t\t\t\t.mean()\n",
    "\t\t\t)\n",
    "\n",
    "\t\ttime = points_effect.shape[0]\n",
    "\t\tenergy_output= []\n",
    "\n",
    "\t\tfor t in range(time):\n",
    "\t\t\ttemp_energy = self.baseline_energy[t] - points_effect.iloc[t]*self.points_multiplier + \\\n",
    "\t\t\t\tnp.random.normal(1)\n",
    "\t\t\tenergy_output.append(temp_energy)\n",
    "\t\t\t\n",
    "\t\treturn pd.DataFrame(energy_output)\n",
    "\n",
    "\tdef pure_linear_signal(self, points, baseline_day=0):\n",
    "\t\t\"\"\"\n",
    "\t\tA linear person. The more points you give them, the less energy they will use\n",
    "\t\t(within some bounds) for each hour. No rolling effects or anything. The simplest\n",
    "\t\tsignal. \n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\t# hack here to always grab the first day from the baseline_energy\n",
    "\t\toutput = np.array(self.baseline_energy)[baseline_day*24:baseline_day*24+10]\n",
    "\n",
    "\t\tpoints_effect = np.array(points * self.points_multiplier)\n",
    "\t\toutput = output - points_effect\n",
    "\n",
    "\t\t# impose bounds/constraints\n",
    "\t\toutput = np.maximum(output, self.min_demand)\n",
    "\t\toutput = np.minimum(output, self.max_demand)\n",
    "\t\treturn output\n",
    "\n",
    "\n",
    "\n",
    "\tdef get_min_demand(self):\n",
    "\t\treturn self.min_demand\n",
    "\t\t# return np.quantile(self.baseline_energy, .05)\n",
    "\n",
    "\tdef get_max_demand(self):\n",
    "\t\treturn self.max_demand\n",
    "\t\t# return np.quantile(self.baseline_energy, .95)\n",
    "\n",
    "class FixedDemandPerson(Person):\n",
    "\n",
    "\tdef __init__(self, baseline_energy_df, points_multiplier = 1):\n",
    "\t\tsuper().__init__(baseline_energy_df, points_multiplier)\n",
    "\n",
    "\n",
    "\tdef demand_from_points(self, points, baseline_day=0):\n",
    "\t\t# hack here to always grab the first day from the baseline_energy\n",
    "\t\toutput = np.array(self.baseline_energy)[baseline_day*24:baseline_day*24+10]\n",
    "\t\ttotal_demand = np.sum(output)\n",
    "\n",
    "\n",
    "\t\tpoints_effect = np.array(points * self.points_multiplier)\n",
    "\t\toutput = output - points_effect\n",
    "\n",
    "\t\t# scale to keep total_demand (almost) constant\n",
    "\t\t# almost bc imposing bounds afterwards\n",
    "\t\toutput = output * (total_demand/np.sum(output))\n",
    "\n",
    "\t\t# impose bounds/constraints\n",
    "\t\toutput = np.maximum(output, self.min_demand)\n",
    "\t\toutput = np.minimum(output, self.max_demand)\n",
    "\n",
    "\t\treturn output\n",
    "\n",
    "\tdef adverserial_linear(self, points, baseline_day=0):\n",
    "\t\t# hack here to always grab the first day from the baseline_energy\n",
    "\t\toutput = np.array(self.baseline_energy)[baseline_day*24:baseline_day*24+10]\n",
    "\t\ttotal_demand = np.sum(output)\n",
    "\n",
    "\n",
    "\t\tpoints_effect = np.array(points * self.points_multiplier)\n",
    "\t\toutput = output + points_effect\n",
    "\n",
    "\t\t# scale to keep total_demand (almost) constant\n",
    "\t\t# almost bc imposing bounds afterwards\n",
    "\t\toutput = output * (total_demand/np.sum(output))\n",
    "\n",
    "\t\t# impose bounds/constraints\n",
    "\t\toutput = np.maximum(output, self.min_demand)\n",
    "\t\toutput = np.minimum(output, self.max_demand)\n",
    "\n",
    "\t\treturn output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CurtailAndShiftPerson(Person):\n",
    "\tdef __init__(self, baseline_energy_df, points_multiplier = 1, shiftable_load_frac = .7, \n",
    "\t\t\tcurtailable_load_frac = .4, shiftByHours = 3, maxCurtailHours=5, response = None, **kwargs):\n",
    "\t\tsuper().__init__(baseline_energy_df, points_multiplier)\n",
    "\t\tself.shiftableLoadFraction = shiftable_load_frac\n",
    "\t\tself.shiftByHours = shiftByHours\n",
    "\t\tself.curtailableLoadFraction = curtailable_load_frac\n",
    "\t\tself.maxCurtailHours = maxCurtailHours #Person willing to curtail for no more than these hours\n",
    "\n",
    "\tdef shiftedLoad(self, points, baseline_day=0, day_of_week=None):\n",
    "\t\toutput = np.array(self.baseline_energy)[baseline_day*24:baseline_day*24+10]\n",
    "\t\tpoints = np.array(points) * self.points_multiplier\n",
    "\t\tshiftableLoad = self.shiftableLoadFraction*output\n",
    "\t\tshiftByHours = self.shiftByHours\n",
    "\t\t\n",
    "\t\t# 10 hour day. Rearrange the sum of shiftableLoad into these hours by treating points as the 'price' at that hour\n",
    "\t\t# Load can be shifted by a max of shiftByHours (default = 3 hours)\n",
    "\t\t# For each hour, calculate the optimal hour to shift load to within +- 3 hours\n",
    "\t\tshiftedLoad = np.zeros(10)\n",
    "\t\tfor hour in range(10):\n",
    "\t\t\tcandidatePrices = points[max(hour-shiftByHours,0): min(hour+shiftByHours,9)+1]\n",
    "\t\t\tshiftToHour = max(hour-shiftByHours,0) + np.argmin(candidatePrices)\n",
    "\t\t\tshiftedLoad[shiftToHour] += shiftableLoad[hour]\t\t\n",
    "\t\treturn shiftedLoad\n",
    "\n",
    "\tdef curtailedLoad(self, points, baseline_day=0, day_of_week=None):\n",
    "\t\toutput = np.array(self.baseline_energy)[baseline_day*24:baseline_day*24+10]\n",
    "\t\tpoints = np.array(points) * self.points_multiplier\n",
    "\t\tcurtailableLoad = self.curtailableLoadFraction*output\n",
    "\t\tmaxPriceHours = np.argsort(points)[0:self.maxCurtailHours]\n",
    "\t\tfor hour in maxPriceHours:\n",
    "\t\t\tcurtailableLoad[hour] = 0\n",
    "\t\treturn curtailableLoad\n",
    "\n",
    "\tdef get_response(self, points, day_of_week=None):\n",
    "\t\tbaseline_day = 0\n",
    "\t\toutput = np.array(self.baseline_energy)[baseline_day*24:baseline_day*24+10]\n",
    "\t\tenergy_resp = output*(1 - self.curtailableLoadFraction - self.shiftableLoadFraction) + self.curtailedLoad(points) + self.shiftedLoad(points)\n",
    "\t\t\n",
    "\t\t\t\n",
    "\t\tself.min_demand = np.maximum(0, min(energy_resp))\n",
    "\t\tself.max_demand = np.maximum(0, max(energy_resp))\n",
    "\n",
    "\t\treturn energy_resp\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\"net_energy_use\":[15.09,  35.6, 123.5,  148.7,  158.49, 149.13, 159.32, 157.62, 158.8,  156.49]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob = CurtailAndShiftPerson(baseline_energy_df=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = []\n",
    "\n",
    "# square_waves = np.array([[0,0,0,0,0,0,0,0,1,0],\n",
    "#                         [0,0,0,0,0,0,0,0,1,0],\n",
    "#                         [1,0,0,0,0,0,0,0,0,0],\n",
    "#                         [1,0,0,0,0,0,0,0,0,0],\n",
    "#                         [0,1,0,0,0,0,0,0,0,0],\n",
    "#                         [0,1,0,0,0,0,0,0,0,0],\n",
    "#                         [0,0,1,0,0,0,0,0,0,1],\n",
    "#                         [0,0,1,0,0,0,0,0,0,1],\n",
    "#                         [0,0,0,1,0,0,0,0,0,0],\n",
    "#                         [0,0,0,1,0,0,0,0,0,0]])\n",
    "train_size = 1000\n",
    "square_waves = np.random.uniform(size=[train_size, 10])\n",
    "square_waves /= np.sum(square_waves, axis=-1, keepdims=True)\n",
    "val_size = 256\n",
    "validation_waves = np.random.uniform(size=[256, 10])\n",
    "validation_waves = validation_waves  / np.sum(validation_waves, axis=-1, keepdims=True)\n",
    "validation_data = []\n",
    "\n",
    "for day in range(square_waves.shape[0]):\n",
    "    output_data.append(bob.get_response(square_waves[day]))\n",
    "for day in range(validation_waves.shape[0]):\n",
    "    validation_data.append(bob.get_response(validation_waves[day]))\n",
    "    \n",
    "output_data=np.array(output_data)\n",
    "validation_data = np.array(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.901462</td>\n",
       "      <td>57.528721</td>\n",
       "      <td>80.574891</td>\n",
       "      <td>101.992539</td>\n",
       "      <td>107.927994</td>\n",
       "      <td>131.965088</td>\n",
       "      <td>144.061344</td>\n",
       "      <td>139.083939</td>\n",
       "      <td>99.867909</td>\n",
       "      <td>107.167921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>78.789229</td>\n",
       "      <td>112.501390</td>\n",
       "      <td>134.160898</td>\n",
       "      <td>167.689655</td>\n",
       "      <td>189.636035</td>\n",
       "      <td>219.111328</td>\n",
       "      <td>230.913096</td>\n",
       "      <td>217.239594</td>\n",
       "      <td>163.842835</td>\n",
       "      <td>150.037648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.509000</td>\n",
       "      <td>-3.560000</td>\n",
       "      <td>-12.350000</td>\n",
       "      <td>-14.870000</td>\n",
       "      <td>-15.849000</td>\n",
       "      <td>-14.913000</td>\n",
       "      <td>-15.932000</td>\n",
       "      <td>-15.762000</td>\n",
       "      <td>-15.880000</td>\n",
       "      <td>-15.649000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.527000</td>\n",
       "      <td>7.003000</td>\n",
       "      <td>-1.787000</td>\n",
       "      <td>20.613000</td>\n",
       "      <td>9.071000</td>\n",
       "      <td>44.739000</td>\n",
       "      <td>47.796000</td>\n",
       "      <td>47.286000</td>\n",
       "      <td>-15.880000</td>\n",
       "      <td>46.947000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.527000</td>\n",
       "      <td>10.680000</td>\n",
       "      <td>37.050000</td>\n",
       "      <td>44.610000</td>\n",
       "      <td>47.547000</td>\n",
       "      <td>44.739000</td>\n",
       "      <td>47.796000</td>\n",
       "      <td>47.286000</td>\n",
       "      <td>47.640000</td>\n",
       "      <td>46.947000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.054000</td>\n",
       "      <td>10.680000</td>\n",
       "      <td>37.050000</td>\n",
       "      <td>44.610000</td>\n",
       "      <td>47.547000</td>\n",
       "      <td>96.030000</td>\n",
       "      <td>93.611000</td>\n",
       "      <td>93.781000</td>\n",
       "      <td>47.640000</td>\n",
       "      <td>93.894000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>224.514000</td>\n",
       "      <td>333.406000</td>\n",
       "      <td>429.007000</td>\n",
       "      <td>538.011000</td>\n",
       "      <td>636.803000</td>\n",
       "      <td>723.979000</td>\n",
       "      <td>746.053000</td>\n",
       "      <td>642.133000</td>\n",
       "      <td>531.072000</td>\n",
       "      <td>426.912000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2            3            4  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean     39.901462    57.528721    80.574891   101.992539   107.927994   \n",
       "std      78.789229   112.501390   134.160898   167.689655   189.636035   \n",
       "min      -1.509000    -3.560000   -12.350000   -14.870000   -15.849000   \n",
       "25%       4.527000     7.003000    -1.787000    20.613000     9.071000   \n",
       "50%       4.527000    10.680000    37.050000    44.610000    47.547000   \n",
       "75%       9.054000    10.680000    37.050000    44.610000    47.547000   \n",
       "max     224.514000   333.406000   429.007000   538.011000   636.803000   \n",
       "\n",
       "                 5            6            7            8            9  \n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \n",
       "mean    131.965088   144.061344   139.083939    99.867909   107.167921  \n",
       "std     219.111328   230.913096   217.239594   163.842835   150.037648  \n",
       "min     -14.913000   -15.932000   -15.762000   -15.880000   -15.649000  \n",
       "25%      44.739000    47.796000    47.286000   -15.880000    46.947000  \n",
       "50%      44.739000    47.796000    47.286000    47.640000    46.947000  \n",
       "75%      96.030000    93.611000    93.781000    47.640000    93.894000  \n",
       "max     723.979000   746.053000   642.133000   531.072000   426.912000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(output_data).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01595884, 0.08764624, 0.04833132, 0.2171418 , 0.13811447,\n",
       "       0.20399528, 0.00293252, 0.10777224, 0.01438616, 0.16372112])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square_waves[:, 1]\n",
    "validation_waves[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0.0001, 1))\n",
    "train_data_normalized = output_data #scaler.fit_transform(output_data.reshape(-1, 1))\n",
    "val_data_normalized = validation_data#scaler.transform(validation_data.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_normalized = train_data_normalized.reshape(-1,10)\n",
    "val_data_normalized = val_data_normalized.reshape([-1, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)\n",
    "        self.hidden2 = torch.nn.Linear(n_hidden, n_hidden)\n",
    "        self.hidden3 = torch.nn.Linear(n_hidden, n_hidden)  \n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      \n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = F.relu(self.hidden3(x))\n",
    "        x = self.predict(x)        \n",
    "        x = x**2 # ensures costs will all be positive     \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden): Linear(in_features=10, out_features=32, bias=True)\n",
      "  (hidden2): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (hidden3): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (predict): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net(n_feature=10, n_hidden=32, n_output=10)     # define the network\n",
    "print(net)  # net architecture\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001, weight_decay=0.001)\n",
    "loss_func = torch.nn.MSELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min loss: 22361.48085003121, best l1 ratio: 0.99, best alpha: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/doseokt5/miniconda3/envs/neural_decoding/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 114917089.67936327, tolerance: 30891.749441355714\n",
      "  positive)\n",
      "/home/doseokt5/miniconda3/envs/neural_decoding/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 123296942.25859807, tolerance: 30891.749441355714\n",
      "  positive)\n",
      "/home/doseokt5/miniconda3/envs/neural_decoding/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 144468577.04461348, tolerance: 30891.749441355714\n",
      "  positive)\n",
      "/home/doseokt5/miniconda3/envs/neural_decoding/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 153176986.24807185, tolerance: 30891.749441355714\n",
      "  positive)\n",
      "/home/doseokt5/miniconda3/envs/neural_decoding/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154326837.78202552, tolerance: 30891.749441355714\n",
      "  positive)\n",
      "/home/doseokt5/miniconda3/envs/neural_decoding/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154445517.73139098, tolerance: 30891.749441355714\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "l1_ratios = [0, 0.1, 0.5, 0.7, 0.95, 0.99, 1]\n",
    "alphas = [10**i for i in range(-4, 2, 1)]\n",
    "min_loss = None\n",
    "best_l1_ratio=None\n",
    "best_alpha=None\n",
    "for l1_ratio in l1_ratios:\n",
    "    for alpha in alphas:\n",
    "        elastic_net = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "        elastic_net.fit(square_waves.reshape(-1, 1), output_data_normalized.reshape(-1, 1))\n",
    "        val_out = elastic_net.predict(validation_waves.reshape(-1, 1))\n",
    "        val_loss = loss_func(torch.tensor(val_data_normalized.reshape(-1, 1)), torch.tensor(val_out.reshape(-1, 1)))\n",
    "        if min_loss is None or val_loss < min_loss:\n",
    "            min_loss = val_loss\n",
    "            best_l1_ratio = l1_ratio\n",
    "            best_alpha = alpha\n",
    "print(\"Min loss: {}, best l1 ratio: {}, best alpha: {}\".format(min_loss, best_l1_ratio, best_alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss:  8173.835\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "val_interval = 50\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "use_ols = False\n",
    "best_model = None\n",
    "best_val_loss = 1000000\n",
    "# train the network\n",
    "for t in range(10000):\n",
    "    net.train()\n",
    "    loss = 0\n",
    "    prediction = net(torch.tensor(square_waves.reshape(-1, 10)).type(torch.FloatTensor))\n",
    "    loss = loss_func(prediction, torch.tensor(output_data_normalized.reshape(-1, 10)).type(torch.FloatTensor))\n",
    "    # for i in range(square_waves.shape[0]):\n",
    "    #     if not use_ols:\n",
    "    #         prediction = net(torch.tensor(square_waves[i].reshape(-1,1)).type(torch.FloatTensor))   \n",
    "    #     else:\n",
    "    #         prediction = torch.tensor(scaler.transform(86 + (5 * (square_waves[i].reshape(-1,1) - 5))))\n",
    "    #     loss +=  loss_func(prediction, torch.tensor(output_data_normalized[i].reshape(-1,1)).type(torch.FloatTensor))     # must be (1. nn output, 2. target)\n",
    "    #loss /= square_waves.shape[1]\n",
    "    if not use_ols:\n",
    "        optimizer.zero_grad()   # clear gradients for next train\n",
    "        loss.backward()         # backpropagation, compute gradients\n",
    "    #print(\"Training epoch {} loss: {}\".format(t, loss))\n",
    "    train_losses.append(loss.detach().numpy())\n",
    "    \n",
    "    optimizer.step()     \n",
    "    if t % val_interval == 0:\n",
    "        loss = 0\n",
    "        net.eval()\n",
    "        prediction = net(torch.tensor(validation_waves.reshape(-1, 10)).type(torch.FloatTensor))\n",
    "        loss = loss_func(prediction, torch.tensor(val_data_normalized.reshape(-1, 10)).type(torch.FloatTensor))\n",
    "        # for i in range(validation_waves.shape[0]):\n",
    "            \n",
    "        #     if not use_ols:\n",
    "        #         prediction = net(torch.tensor(validation_waves[i].reshape(-1,1)).type(torch.FloatTensor))   \n",
    "        #     else:\n",
    "        #         prediction = torch.tensor(scaler.transform(86 + (5 * (validation_waves[i].reshape(-1,1) - 5))))\n",
    "        #     loss +=  loss_func(prediction, torch.tensor(val_data_normalized[i].reshape(-1,1)).type(torch.FloatTensor))     # must be (1. nn output, 2. target)\n",
    "        # loss /= validation_waves.shape[0]\n",
    "        #print(\"Validation epoch {} loss: {}\".format(t, loss))\n",
    "        val_losses.append(loss.detach().numpy())\n",
    "        if loss < best_val_loss:\n",
    "            best_val_loss = loss\n",
    "            \n",
    "            best_model = deepcopy(net)\n",
    "\n",
    "print(\"Best validation loss: \", min(val_losses))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>46.443523</td>\n",
       "      <td>60.907078</td>\n",
       "      <td>79.277534</td>\n",
       "      <td>97.660416</td>\n",
       "      <td>105.110161</td>\n",
       "      <td>128.461578</td>\n",
       "      <td>138.143631</td>\n",
       "      <td>134.029419</td>\n",
       "      <td>95.661644</td>\n",
       "      <td>103.766296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>60.841457</td>\n",
       "      <td>98.636116</td>\n",
       "      <td>121.257469</td>\n",
       "      <td>158.653595</td>\n",
       "      <td>178.970795</td>\n",
       "      <td>211.784897</td>\n",
       "      <td>229.293396</td>\n",
       "      <td>212.017166</td>\n",
       "      <td>155.288849</td>\n",
       "      <td>141.277695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.102811</td>\n",
       "      <td>3.202381</td>\n",
       "      <td>13.991355</td>\n",
       "      <td>6.751064</td>\n",
       "      <td>7.770954</td>\n",
       "      <td>8.884500</td>\n",
       "      <td>8.738140</td>\n",
       "      <td>5.241854</td>\n",
       "      <td>8.363132</td>\n",
       "      <td>9.721380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.149786</td>\n",
       "      <td>15.272701</td>\n",
       "      <td>30.997064</td>\n",
       "      <td>27.159435</td>\n",
       "      <td>28.593267</td>\n",
       "      <td>31.693459</td>\n",
       "      <td>30.675326</td>\n",
       "      <td>26.715020</td>\n",
       "      <td>29.062377</td>\n",
       "      <td>38.010065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.900028</td>\n",
       "      <td>61.991158</td>\n",
       "      <td>67.089514</td>\n",
       "      <td>88.654753</td>\n",
       "      <td>87.059446</td>\n",
       "      <td>102.082151</td>\n",
       "      <td>118.073277</td>\n",
       "      <td>125.211918</td>\n",
       "      <td>79.300571</td>\n",
       "      <td>118.977854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>311.235596</td>\n",
       "      <td>528.840515</td>\n",
       "      <td>642.409912</td>\n",
       "      <td>754.425659</td>\n",
       "      <td>806.571472</td>\n",
       "      <td>857.270752</td>\n",
       "      <td>865.836060</td>\n",
       "      <td>771.904053</td>\n",
       "      <td>672.742615</td>\n",
       "      <td>578.561035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2            3            4  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean     46.443523    60.907078    79.277534    97.660416   105.110161   \n",
       "std      60.841457    98.636116   121.257469   158.653595   178.970795   \n",
       "min       0.000008     0.000042     0.000474     0.000010     0.000014   \n",
       "25%       4.102811     3.202381    13.991355     6.751064     7.770954   \n",
       "50%      20.149786    15.272701    30.997064    27.159435    28.593267   \n",
       "75%      61.900028    61.991158    67.089514    88.654753    87.059446   \n",
       "max     311.235596   528.840515   642.409912   754.425659   806.571472   \n",
       "\n",
       "                 5            6            7            8            9  \n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \n",
       "mean    128.461578   138.143631   134.029419    95.661644   103.766296  \n",
       "std     211.784897   229.293396   212.017166   155.288849   141.277695  \n",
       "min       0.000013     0.000002     0.000013     0.000005     0.000078  \n",
       "25%       8.884500     8.738140     5.241854     8.363132     9.721380  \n",
       "50%      31.693459    30.675326    26.715020    29.062377    38.010065  \n",
       "75%     102.082151   118.073277   125.211918    79.300571   118.977854  \n",
       "max     857.270752   865.836060   771.904053   672.742615   578.561035  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(prediction.detach().numpy()).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f635cb04150>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f635c8b9110>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAlGElEQVR4nO3de3Scd33n8fd3rrpa9ziOZFt24lwcA7kIxyWEAmEbk7KYUGhNKckp2TXlBBbasm0C53SBbs4m7UK26VlCQ5ONSYEkXNqElFDShFAuxkFOHF/iGMuJL7IVR77L1m0u3/1jfnJGRpZkWdJoPJ/XOXPmme88v5nvPBo93+f3+z0zY+6OiIhIpNAJiIjIzKCCICIigAqCiIgEKggiIgKoIIiISBArdAIT1djY6K2trYVOQ0SkqKxbt26/uzeNdF/RFoTW1lba29sLnYaISFExs52nuk9DRiIiAqggiIhIoIIgIiKACoKIiAQqCCIiAqggiIhIoIIgIiJAEX8OYaLW7TzILzoOsPi8WVx9QSNl8WihUxIRmRHG3UMws6iZPW9mj4fb9Wb2pJltC9d1eeveZmYdZrbVzK7Li19pZhvDfXebmYV40sweDvG1ZtY6ia9xmPYdh/jSk7/m5tXt/N1T26bqaUREis7pDBl9CtiSd/tW4Cl3XwQ8FW5jZouBlcClwHLgK2Y2dBh+D7AKWBQuy0P8ZuCQu18A3AXcOaFXMw4f++3z2fSF62isSnLw2OBUPY2ISNEZV0Ewsxbgd4F/zAuvAFaH5dXA+/LiD7n7gLu/AnQAS81sDjDL3dd47mfavn5Sm6HH+g5w7VDvYSpUJWNUl8XoS2Wm6ilERIrOeHsI/wf4CyCbF5vt7l0A4fqcEG8Gduet1xlizWH55PiwNu6eBo4ADScnYWarzKzdzNq7u7vHmfrIyuNRegdVEEREhoxZEMzsPcBr7r5unI850pG9jxIfrc3wgPu97t7m7m1NTSN+Wd+4lSei9KuHICJywnjOMroaeK+ZXQ+UAbPM7J+AfWY2x927wnDQa2H9TmBuXvsWYG+It4wQz2/TaWYxoAY4OMHXNC7l8aiGjERE8ozZQ3D329y9xd1byU0WP+3ufwQ8BtwUVrsJeDQsPwasDGcOLSA3efxsGFbqMbNlYX7gxpPaDD3WB8Jz/EYPYTKVachIRGSYM/kcwh3AI2Z2M7AL+CCAu282s0eAF4E0cIu7D+15Pw48AJQDT4QLwH3Ag2bWQa5nsPIM8hqXCg0ZiYgMc1oFwd2fAZ4JyweAa0+x3u3A7SPE24ElI8T7CQVlupTHo/SphyAickLJfnVFeSJK72C60GmIiMwYJV0Q+lPZsVcUESkRpVsQ4lEGM1nSGRUFEREo8YIA6NRTEZGgdAtCQgVBRCRf6RaE0EPoH9SQkYgIlHJBCD2E3pTONBIRARUEfRZBRCQo3YKgSWURkWFUENRDEBEBSrggVOgsIxGRYUq2IJSphyAiMkzJFgR9DkFEZLjSLQjqIYiIDKOCoB6CiAhQwgUhEjGSsYh6CCIiQckWBMjNI6iHICKSU9IFoUK/miYickJJF4SyRJRe9RBERIASLwjl8Sj96iGIiAAlXhAqNIcgInJCSReEsniUXvUQRESAcRQEMyszs2fN7AUz22xmXwjxz5vZHjNbHy7X57W5zcw6zGyrmV2XF7/SzDaG++42MwvxpJk9HOJrzax1Cl7rbyiPR+lXD0FEBBhfD2EAeKe7vwm4DFhuZsvCfXe5+2Xh8gMAM1sMrAQuBZYDXzGzaFj/HmAVsChclof4zcAhd78AuAu484xf2ThoyEhE5HVjFgTPORZuxsPFR2myAnjI3Qfc/RWgA1hqZnOAWe6+xt0d+Drwvrw2q8Pyd4Brh3oPU6k8oSEjEZEh45pDMLOoma0HXgOedPe14a5PmNkGM7vfzOpCrBnYnde8M8Saw/LJ8WFt3D0NHAEaRshjlZm1m1l7d3f3eFIfVZnOMhIROWFcBcHdM+5+GdBC7mh/Cbnhn/PJDSN1AV8Kq490ZO+jxEdrc3Ie97p7m7u3NTU1jSf1UVWEzyHkOiwiIqXttM4ycvfDwDPAcnffFwpFFvgasDSs1gnMzWvWAuwN8ZYR4sPamFkMqAEOnk5uE1Eej5LJOqmMCoKIyHjOMmoys9qwXA68C3gpzAkMuQHYFJYfA1aGM4cWkJs8ftbdu4AeM1sW5gduBB7Na3NTWP4A8LRPw2F7mb7xVETkhNg41pkDrA5nCkWAR9z9cTN70MwuIze0swP4GIC7bzazR4AXgTRwi7sP7XE/DjwAlANPhAvAfcCDZtZBrmew8sxf2tgqErmX3zeYoaY8Ph1PKSIyY41ZENx9A3D5CPGPjNLmduD2EeLtwJIR4v3AB8fKZbJVJnM9hGMD6el+ahGRGaekP6lcXZarhyoIIiIlXhAqw5DRsX4VBBGRki4IVeohiIicUNoFIamCICIyRAUBOK6CICJS4gVBQ0YiIieUdEFIxqLEo0aPJpVFREq7IEBu2EhDRiIiKghUJmMaMhIRQQWBKhUEERFABYHqspg+mCYiggoClckYxwdVEERESr4gVCXVQxARARUEqsti9GgOQUREBaEyodNORURABYGqshi9gxkyWf2MpoiUNhWEoe8z0sSyiJQ4FYSkfhNBRARUEPQFdyIiQckXhEr9JoKICKCCQLWGjEREgHEUBDMrM7NnzewFM9tsZl8I8Xoze9LMtoXrurw2t5lZh5ltNbPr8uJXmtnGcN/dZmYhnjSzh0N8rZm1TsFrHVGlfiRHRAQYXw9hAHinu78JuAxYbmbLgFuBp9x9EfBUuI2ZLQZWApcCy4GvmFk0PNY9wCpgUbgsD/GbgUPufgFwF3Dnmb+08RmaVNaH00Sk1I1ZEDznWLgZDxcHVgCrQ3w18L6wvAJ4yN0H3P0VoANYamZzgFnuvsbdHfj6SW2GHus7wLVDvYepVl2mISMRERjnHIKZRc1sPfAa8KS7rwVmu3sXQLg+J6zeDOzOa94ZYs1h+eT4sDbungaOAA0j5LHKzNrNrL27u3tcL3AsGjISEckZV0Fw94y7Xwa0kDvaXzLK6iMd2fso8dHanJzHve7e5u5tTU1NY2Q9PvFohGQsorOMRKTkxU5nZXc/bGbPkBv732dmc9y9KwwHvRZW6wTm5jVrAfaGeMsI8fw2nWYWA2qAg6f5WiasKhnj2R0H+YefbCcWjZCIGrFohFjEqErGaKpOsqS5hrJ4dOwHExEpUmMWBDNrAlKhGJQD7yI36fsYcBNwR7h+NDR5DPimmX0ZOI/c5PGz7p4xs54wIb0WuBH4+7w2NwFrgA8AT4d5hmmx+LxZ/HTbfp7fdfiU6yRiEf6gbS5fXHEp0zS9ISIyrcbTQ5gDrA5nCkWAR9z9cTNbAzxiZjcDu4APArj7ZjN7BHgRSAO3uHsmPNbHgQeAcuCJcAG4D3jQzDrI9QxWTsaLG6+vf3Qpg5ks6YyTzjipbJZUuH1sIM2eQ338YGMXD/5yJxeeW81Hls2fzvRERKaFTeOB+KRqa2vz9vb2aXu+bNb56Opf8YvtB3jiU9dwflPVtD23iMhkMbN17t420n0l/0nl8YpEjDve/0YG01me2rKv0OmIiEw6FYTTcG5NGc215bzQeaTQqYiITDoVhNP0xpYaNqogiMhZSAXhNL2xpZZdB3s53DtY6FRERCaVCsJpemNLDQAb96iXICJnFxWE07TkvFxB2KBhIxE5y6ggnKaaijitDRVs6Dxc6FRERCaVCsIEvKGllhd2q4cgImcXFYQJuHJeLa8e7WfP4b5CpyIiMmlUECagrbUegPYd0/b9eyIiU04FYQIuPreaykSU9h2HCp2KiMikUUGYgFg0wuXz6mjfqYIgImcPFYQJamut46VXj3K0P1XoVEREJoUKwgS1za/HnVF/Q0FEpJioIEzQ5fNqiUWMZ185UOhUREQmhQrCBFUmY7yxpYY121UQROTsoIJwBpYtbGBD5xGOD6QLnYqIyBlTQTgDyxY2kM66zjYSkbOCCsIZaGutIxYxfvmyho1EpPipIJyBikSMN82t1TyCiJwVVBDO0DsuamL97sP8el9PoVMRETkjKghn6MNXzaciEeWeZ7YXOhURkTMyZkEws7lm9mMz22Jmm83sUyH+eTPbY2brw+X6vDa3mVmHmW01s+vy4lea2cZw391mZiGeNLOHQ3ytmbVOwWudEnWVCT60dB6PvbCX3Qd7C52OiMiEjaeHkAb+3N0vAZYBt5jZ4nDfXe5+Wbj8ACDctxK4FFgOfMXMomH9e4BVwKJwWR7iNwOH3P0C4C7gzjN/adPnv16zEHfn2+27C52KiMiEjVkQ3L3L3Z8Lyz3AFqB5lCYrgIfcfcDdXwE6gKVmNgeY5e5r3N2BrwPvy2uzOix/B7h2qPdQDM6tKeMNLbX8XJPLIlLETmsOIQzlXA6sDaFPmNkGM7vfzOpCrBnIP1TuDLHmsHxyfFgbd08DR4CGEZ5/lZm1m1l7d3f36aQ+5a4+v4EXdh/mmD6kJiJFatwFwcyqgO8Cn3b3o+SGf84HLgO6gC8NrTpCcx8lPlqb4QH3e929zd3bmpqaxpv6tLj6gkbSWdd3G4lI0RpXQTCzOLli8A13/x6Au+9z94y7Z4GvAUvD6p3A3LzmLcDeEG8ZIT6sjZnFgBqgqH6O7Mr5dSRiEX7eoYIgIsVpPGcZGXAfsMXdv5wXn5O32g3AprD8GLAynDm0gNzk8bPu3gX0mNmy8Jg3Ao/mtbkpLH8AeDrMMxSNsniUtvl1/Lxjf6FTERGZkNg41rka+Aiw0czWh9hngQ+Z2WXkhnZ2AB8DcPfNZvYI8CK5M5RucfdMaPdx4AGgHHgiXCBXcB40sw5yPYOVZ/KiCqWttZ67n9pGfypDWTw6dgMRkRlkzILg7j9j5DH+H4zS5nbg9hHi7cCSEeL9wAfHymWmm19fAcDew30sbKoqcDYiIqdHn1SeRHNDQeg81FfgTERETp8KwiRqqSsHYPchfWJZRIqPCsIkmj2rjFjE1EMQkaKkgjCJohHjvNpyFQQRKUoqCJOspa6cTg0ZiUgRUkGYZHPrKtRDEJGipIIwyVrqyunuGaA/lRl7ZRGRGUQFYZK11OfONFIvQUSKjQrCJGupG/osguYRRKS4qCBMsqHPIqiHICLFRgVhks2uLiMRjejDaSJSdFQQJlkkYrTUl7PrgAqCiBQXFYQpML++gh0qCCJSZFQQpsD8hkp2HThOkf2kg4iUOBWEKTC/oYLjgxn2HxssdCoiIuOmgjAFWhsqAdh18HiBMxERGT8VhCkwryH3WYQd+zWPICLFQwVhCrTUlRMx2HlQBUFEiocKwhRIxqLMqSln5wENGYlI8VBBmCKtjRXs1KmnIlJEVBCmyLz6SvUQRKSojFkQzGyumf3YzLaY2WYz+1SI15vZk2a2LVzX5bW5zcw6zGyrmV2XF7/SzDaG++42MwvxpJk9HOJrzax1Cl7rtFrQWMGh3hSHjuvUUxEpDuPpIaSBP3f3S4BlwC1mthi4FXjK3RcBT4XbhPtWApcCy4GvmFk0PNY9wCpgUbgsD/GbgUPufgFwF3DnJLy2glo8pwaATXuPFDgTEZHxGbMguHuXuz8XlnuALUAzsAJYHVZbDbwvLK8AHnL3AXd/BegAlprZHGCWu6/x3Ed4v35Sm6HH+g5w7VDvoVgtaZ4FwKY9RwuciYjI+JzWHEIYyrkcWAvMdvcuyBUN4JywWjOwO69ZZ4g1h+WT48PauHsaOAI0nE5uM01tRYK59eVs2qMegogUh3EXBDOrAr4LfNrdRzvsHenI3keJj9bm5BxWmVm7mbV3d3ePlXLBLTmvRkNGIlI0xlUQzCxOrhh8w92/F8L7wjAQ4fq1EO8E5uY1bwH2hnjLCPFhbcwsBtQAB0/Ow93vdfc2d29ramoaT+oFtaS5hp0HejnSlyp0KiIiYxrPWUYG3Adscfcv5931GHBTWL4JeDQvvjKcObSA3OTxs2FYqcfMloXHvPGkNkOP9QHgaT8Lvip0SXNuYnmzegkiUgRi41jnauAjwEYzWx9inwXuAB4xs5uBXcAHAdx9s5k9ArxI7gylW9w9E9p9HHgAKAeeCBfIFZwHzayDXM9g5Zm9rJlhyXm5ieWNnUd4y/mNBc5GRGR0VqwH4m1tbd7e3l7oNMb07r/7KUf7UvzoT99GZXI89VdEZOqY2Tp3bxvpPn1SeYr99YpL2Xukj7/9t62FTkVEZFQqCFOsrbWejyybz+o1O/jG2p2FTkdE5JQ0hjENPnv9JXQe6uNz/7yJTNa58bdaC52SiMhvUA9hGpTFo3z1j67kXZfM5gvff5Ff7fiNM2pFRApOBWGaJGIRvvwHb2JuXTmf+OZzHO3XZxNEZGZRQZhGs8rifPkPLmPf0QEe+dXusRuIiEwjFYRpdsW8Oq6cX8eDv9xJNlucp/yKyNlJBaEAbnpLKzsP9PKTX8/872MSkdKhglAA715yLk3VSb6zrnPslUVEpokKQgHEoxEun1vL1n09hU5FROQEFYQCWdhUxc4Dx0lnsoVORUQEUEEomIWNlaQyzp7DfYVORUQEUEEomIVNlQC83H28wJmIiOSoIBTIwqYqALZ3HytwJiIiOSoIBVJfmaC2Is4r+9VDEJGZQQWhgBY0VmrISERmDBWEAlrYWMXL+zVkJCIzgwpCAS1sqmTf0QGOD6QLnYqIiApCIZ0fzjTSxLKIzAQqCAV06Xk1ALzQeaTAmYiIqCAUVEtdOY1VSZ7feajQqYiIqCAUkplxxbxantulgiAihTdmQTCz+83sNTPblBf7vJntMbP14XJ93n23mVmHmW01s+vy4lea2cZw391mZiGeNLOHQ3ytmbVO8muc0a6YX8eOA70cODZQ6FREpMSNp4fwALB8hPhd7n5ZuPwAwMwWAyuBS0Obr5hZNKx/D7AKWBQuQ495M3DI3S8A7gLunOBrKUpXzKsDYP3uw4VNRERK3pgFwd3/Axjvr8KvAB5y9wF3fwXoAJaa2RxglruvcXcHvg68L6/N6rD8HeDaod5DKXhDcw2xiGnYSEQK7kzmED5hZhvCkFJdiDUD+T8W3BlizWH55PiwNu6eBo4ADSM9oZmtMrN2M2vv7j47fm2sPBFl8Xmz+OGmV+lPZQqdjoiUsIkWhHuA84HLgC7gSyE+0pG9jxIfrc1vBt3vdfc2d29ramo6rYRnsj9914Vs7z7OFx9/sdCpiEgJm1BBcPd97p5x9yzwNWBpuKsTmJu3aguwN8RbRogPa2NmMaCG8Q9RnRXecfE5fOy3F/LNtbt4dP2eQqcjIiVqQgUhzAkMuQEYOgPpMWBlOHNoAbnJ42fdvQvoMbNlYX7gRuDRvDY3heUPAE+HeYaS8pnfuYgr59fx2e9t5GV9cllECmA8p51+C1gDXGRmnWZ2M/A34RTSDcA7gD8FcPfNwCPAi8APgVvcfWhg/OPAP5KbaN4OPBHi9wENZtYB/Blw62S9uGISj0b4+w9dTjwW4ZZvPq/5BBGZdlasB+NtbW3e3t5e6DQm3dMv7eOjD7Tz4avmcfsNbyh0OiJyljGzde7eNtJ9+qTyDPPOi2fzsd9eyDfW7uJHm18tdDoiUkJUEGagz/zORVw4u4r/+a9bNHQkItNGBWEGikcj/NV7LmXXwV7u//krhU5HREqECsIM9dZFjbzrknP46jPb6RtUL0FEpp4Kwgz2X65ZyNH+NI9v2Dv2yiIiZ0gFYQa7akE95zdV8o21uwqdioiUABWEGczM+MOr5rN+92E279WvqonI1FJBmOF+74pmkrEI31QvQUSmmArCDFdbkeA9bzyPf3l+D8cG0oVOR0TOYioIReAPr5rH8cEMj63X5LKITB0VhCJwxbxaLj63mgd/uZNi/aoREZn5VBCKgJnx0asXsKXrKE+/9Fqh0xGRs5QKQpG44Ypm5tVXcNe//1q9BBGZEioIRSIejfDJd17Apj1HefLFfYVOR0TOQioIReSGy5tpbajgrn/fRjarXoKITC4VhCISi0b4b9cuYkvXUX70or4aW0QmlwpCkXnvm85jYWMldz25jcF0ttDpiMhZRAWhyMSiEW67/hK27uvhjideKnQ6InIWUUEoQv9p8Wz++OpW7v/5Kzz8K32lhYhMDhWEInXbuy/hrRc08pff3chfP/6ifjNBRM6YCkKRSsQi/L8/fjM3/tZ87vvZK1z7pWf4/gt79RkFEZkwFYQiFo9G+OKKJTy8ahm1FQk++a3n+f1/WMPGTn1VtoicvjELgpndb2avmdmmvFi9mT1pZtvCdV3efbeZWYeZbTWz6/LiV5rZxnDf3WZmIZ40s4dDfK2ZtU7yazzrXbWwge9/8q3c8f438HL3cd77f3/Gnz/yAp2HegudmogUkfH0EB4Alp8UuxV4yt0XAU+F25jZYmAlcGlo8xUzi4Y29wCrgEXhMvSYNwOH3P0C4C7gzom+mFIWjRgrl87jx//97ay6ZiHf37CXd/7vn/CZb7/Axs4jGkoSkTHZeHYU4aj9cXdfEm5vBd7u7l1mNgd4xt0vMrPbANz9f4X1/g34PLAD+LG7XxziHwrtPza0jruvMbMY8CrQ5GMk1tbW5u3t7RN5zSVh7+E+vvqT7Xy7vZO+VIYLZ1fx/itauOHyZmbPKit0eiJSIGa2zt3bRrpvonMIs929CyBcnxPizcDuvPU6Q6w5LJ8cH9bG3dPAEaBhpCc1s1Vm1m5m7d3d3RNMvTScV1vOF1cs4Ze3XcvtNyyhuizOHU+8xFvueJo/eXAdj2/YS09/qtBpisgMEpvkx7MRYj5KfLQ2vxl0vxe4F3I9hIkkWGpqKuJ8+Kr5fPiq+byy/zgPPbuLb6/r5IebXyUeNZYtbOBNLbUsPm8WyxY2UF+ZKHTKIlIgEy0I+8xsTt6Q0dCX9HcCc/PWawH2hnjLCPH8Np1hyKgGODjBvGQUCxorue36S/iL5RezbuchnnzxVZ7Z2s0vtm8nE74s75I5s3jL+Q381sIGrpxfR50KhEjJmGhBeAy4CbgjXD+aF/+mmX0ZOI/c5PGz7p4xsx4zWwasBW4E/v6kx1oDfAB4eqz5Azkz0YixdEE9SxfU87nfhYF0hs17j7Jm+wF+sX0///TLndz3s1cAmFdfwRtbanjnxedw3aXnUpmc7E6liMwUY04qm9m3gLcDjcA+4H8A/wI8AswDdgEfdPeDYf3PAR8F0sCn3f2JEG8jd8ZSOfAE8El3dzMrAx4ELifXM1jp7i+PlbgmladOfyrD+t2HWb/7MBs6D/PczsO8erSfZCzC0gX1vG1RE9dc2MhFs6sJZw+LSJEYbVJ5XGcZzUQqCNPH3WnfeYh/3dDFzzr20/HaMQCaqpNcc0Ej11zYyNUXNHJOtc5ekrNfKpPlSF+KvsEMqUyWdNbpT2Xo6U+TdSdqhpmRyTqpTJZUJstgJstAKnc9mM4ykM4wmM5yfDBDfypDdTLGQDpL97EB4pEIZfEIiViEVCb32P2pDAPpLKlMbn/9R8vm8faLzhkj05GNVhDU/5cxmRlvbq3nza31AHQd6eOn2/bz0237eebX3Xzv+T0AXHxuNW+7sIlrFjXy5tZ6yuLR0R5WZEL6Uxni0QiZrNOXypCMRegbzNB9bIBUJot7bqe9/9ggR/pSZN2pTsZIxCIc7k1xqHeQnv40A+nhO+f+dPb1nW8qS386t+wOETN6+lMc6UtxfBK/NyweNcpiUY4NpolHIzRVJUlns/SncrklYhGSsQhl8Shl8QjRSO7E0OMDU/PdZeohyBnJZp0Xu47yH9u6+dm2/bTvOMRgJsusshi/d2ULyy89lyvm1xGP6ltSSoW7M5DOcrQ/xdG+NH2DGSqTUSJmHOlLcTgcXUcjRnfPAD39KRKxCP2poTYpuo70c+D4IMlYBHfP7bBTWfb19HO4d3JOl05EczvbRLiUxaPDdr5l8ShlsShmkMk61WVxaivi1JTnrisSMeJRIxbJPU51WYxIxMhmnaxDLGrEIkY873mSseiJnXwiFjnxf5HNOmZMyxCshoxk2vQOpln78kG+9/wefripi1TGqS6L8dYLGrlsbi0Xz5nFJedW01SdnDHzD+5OfyrL4b5BDvemONybOxI8MnS7L0Um65TFIiTjURLRyIl/3ojlzpuORAxjKJaLR8zIupPOOpns0HVuiKEqGaOuIsFA+JGjsniEsliUaMRIZbJksrmdau9ghljUhu2sMtks+3sGiUWNZCxKOps7mkyHIYrBMLSQymRJZ7JkHeoqEyRjEdJhiCOd9deXM8NvZ7JOIhYh685rRwfoT2VIDeUe1h16nqGhkIFwpD101D1R8ahRXRbn3FllNFQlGExniZiRjEdIRCM0VSeZU1NGOpsbmilPRBnMZEnGojRVJ0lEI0QjRjQCDZVJaivi4eg+zWAmS11FnNryxImddynSkJFMm4pEjHdcfA7vuPgcjvYv4Rcd+/nxS938rGM/T2x6/Wc/GyoTLJpdxbz6CuY3VNJcW059ZYL6ygQ15XGSsQixaIR4NHeEFQ//6GPJhmGE3sEMvYNpjg9kONKXYv+xAbp7Bug+NsD+cN3dM8D+YwMcOp5iMHPqnVgsYsSiRn+q+H6hzkLBGu0nuCOW++GlWCR3RBuNGIPpLGbGOdVJKpJRopHX7y+LR5hVFsv9XcLRbjKWK1jJ+OvLs8rjzCqLUZGIcXwgTSbr1FXGqSlPUBbPDfk0VCWpLY8zmM5Snsi1mykHCqVIPQSZNod7B3np1R5e6jrKlq4eOrqPsetgL909A+Nqb5b7htd4xIjHIsQiERJRIxLJ7ax7B9P0jjG+G4sYjVVJmqpzl8aqBHWVCWrLE68PB5THqamIU1uRK06ViShmdmIoJJXJ4oBnwckND7i/fu1A1nNH2tGwg41FIuE6d7unP82h3kHKYrl5lqHx6kzWiUcjJ47+y+PRE2PKQxOLEYPGqiTZ0LPJL5rxaG7bJMIOfqiIHunLFb1YJHJiKCMWdvKleqRcqtRDkBmhtiLBsoUNLFs4/JtJegfTdB3p5+DxQQ4cG+Ro2HmlM2HoI5sllfbc0EgmN2yRyrw+LJLJOmXxKJWJKBXJ2PDrRIxZZTEaq5M0VSWpKY9PeAdoZmF8+cwny8viuSGO6VJboQ8YythUEKTgKhIxzm+q4vymQmciUtp06oeIiAAqCCIiEqggiIgIoIIgIiKBCoKIiAAqCCIiEqggiIgIoIIgIiJB0X51hZl1Azsn2LwR2D+J6UymmZqb8jo9yuv0zdTczra85rv7iB8DLdqCcCbMrP1U3+VRaDM1N+V1epTX6ZupuZVSXhoyEhERQAVBRESCUi0I9xY6gVHM1NyU1+lRXqdvpuZWMnmV5ByCiIj8plLtIYiIyElUEEREBCjBgmBmy81sq5l1mNmtBcxjrpn92My2mNlmM/tUiH/ezPaY2fpwub4Aue0ws43h+dtDrN7MnjSzbeG6bppzuihvm6w3s6Nm9ulCbS8zu9/MXjOzTXmxU24jM7stvOe2mtl105zX35rZS2a2wcz+2cxqQ7zVzPrytt1XpzmvU/7tpmt7jZLbw3l57TCz9SE+LdtslP3D1L7H3L1kLkAU2A4sBBLAC8DiAuUyB7giLFcDvwYWA58HPlPg7bQDaDwp9jfArWH5VuDOAv8dXwXmF2p7AW8DrgA2jbWNwt/1BSAJLAjvweg05vU7QCws35mXV2v+egXYXiP+7aZze50qt5Pu/xLwV9O5zUbZP0zpe6zUeghLgQ53f9ndB4GHgBWFSMTdu9z9ubDcA2wBmguRyzitAFaH5dXA+wqXCtcC2919op9UP2Pu/h/AwZPCp9pGK4CH3H3A3V8BOsi9F6clL3f/kbunw81fAi1T8dynm9copm17jZWbmRnw+8C3pur5T5HTqfYPU/oeK7WC0AzszrvdyQzYCZtZK3A5sDaEPhG69/dP99BM4MCPzGydma0Ksdnu3gW5NytwTgHyGrKS4f+ghd5eQ061jWbS++6jwBN5txeY2fNm9hMzu6YA+Yz0t5tJ2+saYJ+7b8uLTes2O2n/MKXvsVIrCDZCrKDn3ZpZFfBd4NPufhS4BzgfuAzoItddnW5Xu/sVwLuBW8zsbQXIYURmlgDeC3w7hGbC9hrLjHjfmdnngDTwjRDqAua5++XAnwHfNLNZ05jSqf52M2J7BR9i+MHHtG6zEfYPp1x1hNhpb7NSKwidwNy82y3A3gLlgpnFyf2xv+Hu3wNw933unnH3LPA1prCrfCruvjdcvwb8c8hhn5nNCXnPAV6b7ryCdwPPufu+kGPBt1eeU22jgr/vzOwm4D3Ahz0MOofhhQNheR25cecLpyunUf52Bd9eAGYWA94PPDwUm85tNtL+gSl+j5VaQfgVsMjMFoQjzZXAY4VIJIxN3gdscfcv58Xn5K12A7Dp5LZTnFelmVUPLZObkNxEbjvdFFa7CXh0OvPKM+yIrdDb6ySn2kaPASvNLGlmC4BFwLPTlZSZLQf+Enivu/fmxZvMLBqWF4a8Xp7GvE71tyvo9srzLuAld+8cCkzXNjvV/oGpfo9N9Wz5TLsA15Obsd8OfK6AebyVXJduA7A+XK4HHgQ2hvhjwJxpzmshubMVXgA2D20joAF4CtgWrusLsM0qgANATV6sINuLXFHqAlLkjs5uHm0bAZ8L77mtwLunOa8OcuPLQ++zr4Z1fy/8jV8AngP+8zTndcq/3XRtr1PlFuIPAH9y0rrTss1G2T9M6XtMX10hIiJA6Q0ZiYjIKaggiIgIoIIgIiKBCoKIiAAqCCIiEqggiIgIoIIgIiLB/wc2Ctus2c1vcgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model.state_dict(), 'model_weights.pth')\n",
    "#torch.save(scaler, \"model_scaler.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(feature_range=(0.0001, 1))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['feature_range', 'copy', 'clip'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MinMaxScaler' object has no attribute 'scale_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-603f17f88c0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'MinMaxScaler' object has no attribute 'scale_'"
     ]
    }
   ],
   "source": [
    "scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d5baaeede1983d6b0a91ed42566590757dbb2e705f1cc78a48bc7026a73a848"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('neural_decoding': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}